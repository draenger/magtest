{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import tiktoken\n",
    "# from ai_models.anthropic_model import AnthropicModel\n",
    "\n",
    "# tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# # (\"claude-3-haiku-20240307\", 0.25, 1.25, rpm_limit, 50_000, 5_000_000),\n",
    "# model = AnthropicModel(\"claude-3-haiku-20240307\", rpm_limit=50, tpm_limit=50_000, tpd_limit=5_000_000, tokenizer=tokenizer, input_cost_per_million=0.25, output_cost_per_million=1.25)\n",
    "\n",
    "# response = model.predict(\"What is the capital of Poland?\")\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alert-maker-440321-u0 us-central1 magtest-bucket magtest-bucket C:\\Users\\dkwar\\Desktop\\ks\\alert-maker-440321-u0-d0e4a63da338.json\n",
      "Service Account: vertex-ai-service@alert-maker-440321-u0.iam.gserviceaccount.com\n",
      "BatchPredictionJob created. Resource name: projects/524644790903/locations/us-central1/batchPredictionJobs/6407167993821790208\n",
      "To use this BatchPredictionJob in another session:\n",
      "job = batch_prediction.BatchPredictionJob('projects/524644790903/locations/us-central1/batchPredictionJobs/6407167993821790208')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/6407167993821790208?project=524644790903\n",
      "Job resource name: projects/524644790903/locations/us-central1/batchPredictionJobs/6407167993821790208\n",
      "Model resource name with the job: publishers/google/models/gemini-1.5-flash-002\n",
      "Job state: JOB_STATE_PENDING\n",
      "Job succeeded!\n",
      "Job output location: gs://magtest-bucket/gemini-1.5-flash-002/prediction-model-2024-11-04T19:27:22.129165Z\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import vertexai\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from vertexai.batch_prediction import BatchPredictionJob\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "location = os.getenv(\"GOOGLE_CLOUD_LOCATION\")\n",
    "input_bucket = os.getenv(\"GOOGLE_CLOUD_INPUT_BUCKET\")\n",
    "output_bucket = os.getenv(\"GOOGLE_CLOUD_OUTPUT_BUCKET\")\n",
    "credentials_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "\n",
    "print(project_id, location, input_bucket, output_bucket, credentials_path)\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    credentials_path,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "\n",
    "# Print service account email\n",
    "print(f\"Service Account: {credentials.service_account_email}\")\n",
    "\n",
    "vertexai.init(\n",
    "    project=project_id,\n",
    "    location=location,\n",
    "    credentials=credentials,\n",
    ")\n",
    "\n",
    "\n",
    "input_uri = \"gs://cloud-samples-data/batch/prompt_for_batch_gemini_predict.jsonl\"\n",
    "output_uri = f\"gs://{output_bucket}/gemini-1.5-flash-002\"\n",
    "\n",
    "# Submit a batch prediction job with Gemini model\n",
    "batch_prediction_job = BatchPredictionJob.submit(\n",
    "    source_model=\"gemini-1.5-flash-002\",\n",
    "    input_dataset=input_uri,\n",
    "    output_uri_prefix=output_uri,\n",
    ")\n",
    "\n",
    "# Check job status\n",
    "print(f\"Job resource name: {batch_prediction_job.resource_name}\")\n",
    "print(f\"Model resource name with the job: {batch_prediction_job.model_name}\")\n",
    "print(f\"Job state: {batch_prediction_job.state.name}\")\n",
    "\n",
    "# Refresh the job until complete\n",
    "while not batch_prediction_job.has_ended:\n",
    "    time.sleep(5)\n",
    "    batch_prediction_job.refresh()\n",
    "\n",
    "# Check if the job succeeds\n",
    "if batch_prediction_job.has_succeeded:\n",
    "    print(\"Job succeeded!\")\n",
    "else:\n",
    "    print(f\"Job failed: {batch_prediction_job.error}\")\n",
    "\n",
    "# Check the location of the output\n",
    "print(f\"Job output location: {batch_prediction_job.output_location}\")\n",
    "\n",
    "# Example response:\n",
    "#  Job output location: gs://your-bucket/gen-ai-batch-prediction/prediction-model-year-month-day-hour:minute:second.12345"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
